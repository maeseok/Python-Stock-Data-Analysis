-인공지능 기술의 분류
머신러닝 : 컴퓨터 시스템이 사용하는 알고리즘과 통계적 모델에 대한 과학적인 연구다.
          컴퓨터는 명시적인 지시 사항들을 이용하는 대신에 모델과 추론에 의존하여 효과적으로 작업을 수행한다.
          머신러닝은 인공지능의 하위 집합으로 간주된다.
즉 컴퓨터 프로그램이 수행하는 작업 T가 경험 E를 통해서 성능 P만큼 향상된 것으로 측정될 때, 우리는 컴퓨터 프로그램이 학습한다고 말한다.

- 머신러닝 알고리즘
1. 퍼셉트론 알고리즘
- 신경망 알고리즘의 기초이다. 퍼셉트론은 신경 세포를 인공적으로 모델링한 것으로, 신경 세포처럼 다른 신경 세포로부터 정보를 받아서 새로운 정보를
  생성한 후, 또 다른 신경 세포로 전달한다.

  x1과 x2는 입력 신호, y는 출력 신호, w1, w2는 가중치를 나타낸다.
  가중치는 결합 하중이라고도 하며 각각의 입력 신호에 곱하는 값으로, 입력 신호가 결과에 미치는 중요도를 결정하는 매개변수다.
  가중치 값이 클수록 전달 효율이 좋아 더 많은 정보를 전달할 수 있다.
  임계값 이하일 때는 0을 출력, 입계값을 넘을 때는 1을 출력, 이 상태를 활성화한다 라고 표현한다.
  퍼셉트론은 구조를 변경하지 않으면서 매개변수(가중치와 임계값)만 변경함으로써 AND, NAND, OR 세 가지의 논리 회로를 만들 수 있다.
  퍼셉트론은 입력 신호의 합이 일정값을 초과하면 그 결과를 다른 퍼셉트론으로 전달한다.
  이는 신경 세포와 매우 유사하다. 

2. 활성화 함수
- 입력 신호의 총합이 임계값을 넘어 설 때 특정값을 출력한느 함수를 활성화 함수라고 한다.
- 활성화 함수는 계단 함수, 시그모이드 함수, ReLU 함수 등으로 나뉜다.

계단함수 
- 출력 신호가 계단 모양과 비슷하다. 0 또는 1이 출력된다.

시그모이드 함수
- 라틴 문자 S를 닮았다는 의미를 가지고 있으며, 출력되는 결과가 S자와 유사하다.
  0~1 사이의 연속적인 실수가 출력된다. 즉 시그모이드는 아날로그, 계단은 디지털 형태라고 봐도 무방하다.

tanh  함수
- 쌍곡탄젠드 함수는 시그모이드 함수와 비슷하지만, -1~1사이의 값을 출력한다는 차이가 있다.

ReLU 함수
- 최근 들어 신경망 분야에서 ReLu 함수가 주로 사용되고 있다. ReLU함수는 음수를 0으로 만든다.
  0이 넘으면 입력 받은 값을 그대로 출력한다.

소프트맥스 함수
- 분류 문제를 다룰 때 사용되는 함수로, 0~1 사이 값을 입력받아 정규화한다.
  출력값들의 총합은 항상 1이 된다.

3. 다층 퍼셉트론
- 단층 퍼셉트론에서는 불가했던 비선형 문제를 해결하며, XOR 게이트를 만들 수 있다.
  입력층과 출력층 사이를 은닉충이라고 부르며, 은닉충이 무수히 많은 신경망을 심층 신경망이라고 부른다.
  활성화 함수는 풀고자 하는 문제의 종류에 따라 적당한 함수를 골라서 사용해야 하는데, 일반적으로 회귀 문제는
  항등 함수, 2 클래스 분류 문제인 경우에는 시그모이드 함수, 다중 클래스 분류 문제에는 소프트맥스 함수를 사용한다.


- 딥러닝
기존 머신러닝에서는 사람이 기계가 학습할 데이터 특징을 설계했지만, 딥러닝에서는 데이터 입력에서부터 결과 출력까지 사람의 개입을 배제할 수 있다.
과적합을 더욱 효과적으로 방지할 수 있는 드롭아웃 개념이 나오고, 컴퓨팅 파워 증가로 빅데이터에 대한 처리가 가능해지면서 딥러닝뿐 아니라 머신러닝 기술 전반이 폭발적으로 발전했다.

- 딥러닝의 학습
학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻한다.
손실 함수는 신경망이 학습할 수 있도록 해주는 지표인데, 이 손실 함수의 결괏값을 가장 작게 만드는
가중치 매개변수를 찾는 것이 학습의 목표다.

-텐서플로 기초
구글 브레인팀에서 심층 신경망 연구를 위해 개발한 머신러닝 라이브러리이다.
현재는 더 높은 수준의 직관적인 케라스 API를 사용할 수 있어, 전체 코드가 깔끔해지고 구현 과정에서 일어나는 실수가 줄어들었다.

-텐서의 차원
텐서플로에서 모든 데이터는 텐서 데이터 구조를 사용해서 표현한다. 
텐서는 동적 크기를 지니는 다차원 데이터 배열을 의미한다.
텐서는 n차원의 배열이나 리스트로도 표현할 수 있으며, 프로그램 내에서 모든 데이터는 텐서의 형태로 이동한다.
각각의 텐서는 차원, 형태, 자료형을 지니는데, 차원은 동적으로 변할 수 있다.

EX) 428 표

- 텐서플로로 선형 회귀 문제 풀기
머신러닝에서 h(x) = wx+b 에서 가중치(w)와 편향(b) 값을 알아내는 것과 똑같다.

- 경사 하강 알고리즘
예측값과 실젯값이 얼마나 차이가 나는지 수치화한 것을 비용 또는 손실이라 한다.
비용 함수는 예측값과 실젯값의 차이를 제곱해서 평균 낸 값을 반환하는데, 이를 오차제곱평균이라 한다.
이렇게 비용 함수의 경사를 타고 내려가며 최솟값을 구해가는 방식을 경사 하강 알고리즘이라 한다.

-RNN을 이용한 주가예측
순환 신경망을 이용한 주가 예측 원리 알아보기
순환 신경망에서 뉴런을 셀이라고도 부르는데, 이전의 데이터를 통해 학습된 셸의 
상태 정보가 다음 데이터를 이용하여 학습시킬 때 다시 사용된다는 의미다.
셀에서 만들어지는 상태 데이터를 은닉 상태라고 한다.
활성화 함수로 쌍곡탄젠트 함수를 사용하여 계산할 수 있다.
셀에서 사용하는 이전의 은닉 상태는 과거 문맥에 관한 정보를 가지고 있어서 앞으로 발생할 데이터를 예측하는 데 활용된다.

-장단기 기억(LSTM)
데이터들의 연관 정보를 파악하려면 기억을 더 길게 유지하는 것을 가능하게 한다.
LSTM은 은닉 상태와 더불어 셀 상태를 계산하는데, 셀 상태를 계산하려면 망각 게이트와 입력 게이트를 이용한다.
망각 게이트 : 이전 셀 상태에서 지울 정보를 학습시킬 용도
입력 게이트 : 새로운 데이터를 학습하는 용도
망각 게이트+입력 게이트 = 현재 셀 상태

즉 텐서플로에서 RNN, LSTM을 구현해두었기에, 개념만 이해한 후 사용하면 된다.
학습 과정에서 사용된 적이 없는 테스트용 데이터셋을 분리해야 과적합 현상을 방지할 수 있다.

